#!/bin/bash

# EchoLayer Performance Optimizer Script
# Description: Comprehensive performance optimization for all system components
# Version: 1.0.0

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"
LOG_FILE="$PROJECT_ROOT/logs/performance-optimization.log"

# Create logs directory if it doesn't exist
mkdir -p "$PROJECT_ROOT/logs"

# Logging function
log() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

print_header() {
    echo -e "${BLUE}=====================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}=====================================${NC}"
    log "$1"
}

print_success() {
    echo -e "${GREEN}✅ $1${NC}"
    log "SUCCESS: $1"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
    log "WARNING: $1"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
    log "ERROR: $1"
}

# Check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# ====================================
# DATABASE OPTIMIZATIONS
# ====================================
optimize_database() {
    print_header "DATABASE PERFORMANCE OPTIMIZATION"
    
    # Check if PostgreSQL is available
    if command_exists psql; then
        echo "Applying PostgreSQL optimizations..."
        
        # Create database optimization SQL
        cat > "$PROJECT_ROOT/temp_db_optimize.sql" << 'EOF'
-- PostgreSQL Performance Optimization Script
-- Generated by EchoLayer Performance Optimizer

-- Update table statistics
ANALYZE;

-- Reindex all tables to improve query performance
REINDEX DATABASE echolayer;

-- Update PostgreSQL configuration recommendations
-- Note: These should be applied to postgresql.conf

-- Memory settings (adjust based on available RAM)
-- shared_buffers = 256MB              -- 25% of RAM for dedicated server
-- effective_cache_size = 1GB          -- 50-75% of total RAM
-- work_mem = 16MB                     -- Per connection sort/hash memory
-- maintenance_work_mem = 64MB         -- For maintenance operations

-- Checkpoint settings
-- wal_buffers = 16MB                  -- WAL buffer size
-- checkpoint_completion_target = 0.9  -- Spread checkpoints over time
-- max_wal_size = 1GB                  -- Maximum WAL size before checkpoint

-- Query planning
-- random_page_cost = 1.1              -- SSD optimization
-- effective_io_concurrency = 200      -- SSD concurrent I/O capability

-- Connection settings
-- max_connections = 200               -- Maximum concurrent connections

-- Vacuum and autovacuum settings
-- autovacuum = on
-- autovacuum_max_workers = 3
-- autovacuum_naptime = 1min

-- Create additional performance indexes
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_content_echo_index_created 
ON content(echo_index DESC, created_at DESC) 
WHERE status = 'active';

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_propagations_content_created 
ON propagations(content_id, created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_rewards_user_status_created 
ON rewards(user_id, status, created_at DESC);

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_analytics_events_user_type_created 
ON analytics_events(user_id, event_type, created_at DESC);

-- Create partial indexes for common queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_users_active_echo_score 
ON users(echo_score DESC) 
WHERE is_active = TRUE;

CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_content_active_platform_echo 
ON content(platform, echo_index DESC) 
WHERE status = 'active';

-- Create composite indexes for complex queries
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_content_user_platform_created 
ON content(user_id, platform, created_at DESC) 
WHERE status = 'active';

-- Update table statistics after index creation
ANALYZE;

SELECT 'Database optimization completed successfully' as result;
EOF
        
        # Apply database optimizations (commented out as it requires database connection)
        # psql "$DATABASE_URL" -f "$PROJECT_ROOT/temp_db_optimize.sql"
        
        print_success "Database optimization SQL script created at temp_db_optimize.sql"
        print_warning "Manual execution required: psql \$DATABASE_URL -f temp_db_optimize.sql"
        
        # Clean up temp file
        # rm "$PROJECT_ROOT/temp_db_optimize.sql"
        
    else
        print_warning "PostgreSQL client not found, skipping database optimizations"
    fi
}

# ====================================
# REDIS CACHE OPTIMIZATIONS
# ====================================
optimize_redis() {
    print_header "REDIS CACHE OPTIMIZATION"
    
    # Create Redis optimization configuration
    cat > "$PROJECT_ROOT/docker/redis/redis-optimized.conf" << 'EOF'
# Redis Performance Optimization Configuration
# Generated by EchoLayer Performance Optimizer

# Memory optimization
maxmemory 512mb
maxmemory-policy allkeys-lru

# Persistence settings (optimized for performance)
save 900 1
save 300 10
save 60 10000

# Disable RDB snapshots for maximum performance (use AOF instead)
# save ""

# AOF persistence (more durable but slightly slower)
appendonly yes
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# Network optimization
tcp-keepalive 300
timeout 300

# Client optimization
tcp-backlog 511

# Memory efficiency
hash-max-ziplist-entries 512
hash-max-ziplist-value 64
list-max-ziplist-size -2
list-compress-depth 0
set-max-intset-entries 512
zset-max-ziplist-entries 128
zset-max-ziplist-value 64

# CPU optimization
hz 10

# Security
requirepass ${REDIS_PASSWORD}

# Logging
loglevel notice
logfile /var/log/redis/redis-server.log

# Slow log
slowlog-log-slower-than 10000
slowlog-max-len 128
EOF
    
    mkdir -p "$PROJECT_ROOT/docker/redis"
    print_success "Redis optimization configuration created"
}

# ====================================
# FRONTEND OPTIMIZATIONS
# ====================================
optimize_frontend() {
    print_header "FRONTEND PERFORMANCE OPTIMIZATION"
    
    cd "$PROJECT_ROOT/frontend"
    
    # Create Next.js optimization configuration
    cat > "next.config.optimized.js" << 'EOF'
/** @type {import('next').NextConfig} */
const nextConfig = {
  // Performance optimizations
  experimental: {
    optimizeCss: true,
    optimizePackageImports: ['@echolayer/shared'],
  },
  
  // Compiler optimizations
  compiler: {
    removeConsole: process.env.NODE_ENV === 'production',
    reactRemoveProperties: process.env.NODE_ENV === 'production' ? { properties: ['^data-test'] } : false,
  },
  
  // Image optimization
  images: {
    domains: ['echolayers.xyz', 'api.echolayers.xyz'],
    formats: ['image/webp', 'image/avif'],
    minimumCacheTTL: 60 * 60 * 24 * 7, // 7 days
  },
  
  // Bundle analysis
  webpack: (config, { isServer }) => {
    // Optimize bundle size
    if (!isServer) {
      config.resolve.fallback = {
        ...config.resolve.fallback,
        fs: false,
        net: false,
        tls: false,
      };
    }
    
    // Enable gzip compression
    if (process.env.NODE_ENV === 'production') {
      const CompressionPlugin = require('compression-webpack-plugin');
      config.plugins.push(
        new CompressionPlugin({
          algorithm: 'gzip',
          test: /\.(js|css|html|svg)$/,
          threshold: 8192,
          minRatio: 0.8,
        })
      );
    }
    
    return config;
  },
  
  // Headers for performance
  async headers() {
    return [
      {
        source: '/(.*)',
        headers: [
          {
            key: 'X-DNS-Prefetch-Control',
            value: 'on'
          },
          {
            key: 'X-Frame-Options',
            value: 'DENY'
          },
        ],
      },
      {
        source: '/static/(.*)',
        headers: [
          {
            key: 'Cache-Control',
            value: 'public, max-age=31536000, immutable',
          },
        ],
      },
    ];
  },
  
  // Redirect optimizations
  async redirects() {
    return [];
  },
  
  // Output optimization
  output: 'standalone',
  
  // Enable SWC minification
  swcMinify: true,
  
  // Reduce bundle size
  modularizeImports: {
    '@mui/icons-material': {
      transform: '@mui/icons-material/{{member}}',
    },
    'lodash': {
      transform: 'lodash/{{member}}',
    },
  },
};

module.exports = nextConfig;
EOF
    
    # Create performance monitoring component
    mkdir -p "src/components/performance"
    cat > "src/components/performance/PerformanceMonitor.tsx" << 'EOF'
'use client';

import { useEffect } from 'react';

interface PerformanceEntry {
  name: string;
  entryType: string;
  startTime: number;
  duration: number;
}

export const PerformanceMonitor: React.FC = () => {
  useEffect(() => {
    if (typeof window === 'undefined' || process.env.NODE_ENV !== 'production') {
      return;
    }

    // Monitor Core Web Vitals
    const observer = new PerformanceObserver((list) => {
      list.getEntries().forEach((entry: PerformanceEntry) => {
        // Log performance metrics
        if (entry.entryType === 'measure' || entry.entryType === 'navigation') {
          console.log(`Performance: ${entry.name} took ${entry.duration}ms`);
          
          // Send to analytics if needed
          if (window.gtag) {
            window.gtag('event', 'performance_metric', {
              event_category: 'performance',
              event_label: entry.name,
              value: Math.round(entry.duration),
            });
          }
        }
      });
    });

    // Observe navigation and measure entries
    observer.observe({ entryTypes: ['navigation', 'measure'] });

    // Cleanup observer
    return () => {
      observer.disconnect();
    };
  }, []);

  return null;
};

// Web Vitals monitoring
export const reportWebVitals = (metric: any) => {
  if (process.env.NODE_ENV === 'production') {
    console.log('Web Vital:', metric);
    
    // Send to analytics
    if (window.gtag) {
      window.gtag('event', metric.name, {
        event_category: 'web_vitals',
        value: Math.round(metric.value),
        event_label: metric.id,
        non_interaction: true,
      });
    }
  }
};
EOF
    
    # Create bundle analyzer script
    cat > "analyze-bundle.js" << 'EOF'
const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer');

/** @type {import('next').NextConfig} */
const nextConfig = {
  webpack: (config) => {
    if (process.env.ANALYZE === 'true') {
      config.plugins.push(
        new BundleAnalyzerPlugin({
          analyzerMode: 'static',
          openAnalyzer: false,
          reportFilename: './bundle-analysis.html',
        })
      );
    }
    return config;
  },
};

module.exports = nextConfig;
EOF
    
    print_success "Frontend optimization configurations created"
    
    # Install performance optimization packages
    if [ -f "package.json" ]; then
        echo "Installing performance optimization packages..."
        npm install --save-dev @next/bundle-analyzer compression-webpack-plugin
        print_success "Performance packages installed"
    fi
    
    cd "$PROJECT_ROOT"
}

# ====================================
# BACKEND OPTIMIZATIONS
# ====================================
optimize_backend() {
    print_header "BACKEND PERFORMANCE OPTIMIZATION"
    
    cd "$PROJECT_ROOT/backend"
    
    # Create Rust optimization configuration
    cat > "Cargo.optimized.toml" << 'EOF'
[package]
name = "echolayer-backend"
version = "0.1.0"
edition = "2021"

[dependencies]
# Core dependencies with optimized features
tokio = { version = "1.0", features = ["full", "tracing"] }
axum = { version = "0.7", features = ["macros", "multipart"] }
tower = { version = "0.4", features = ["util", "timeout", "load-shed", "limit"] }
tower-http = { version = "0.5", features = ["fs", "cors", "compression-gzip"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
sqlx = { version = "0.7", features = ["runtime-tokio-rustls", "postgres", "uuid", "chrono", "json"] }
redis = { version = "0.24", features = ["tokio-comp", "connection-manager"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

# Performance optimizations
dashmap = "5.5"          # High-performance concurrent HashMap
once_cell = "1.19"       # Lazy static initialization
rayon = "1.8"           # Data parallelism
parking_lot = "0.12"     # Faster mutexes
ahash = "0.8"           # Faster hashing algorithm

# Memory optimization
jemalloc_ctl = "0.5"    # Memory profiling
tikv-jemallocator = "0.5" # Better memory allocator

[profile.release]
# Maximum optimization for production
opt-level = 3
lto = true
codegen-units = 1
panic = "abort"
strip = true

[profile.dev]
# Faster compilation for development
opt-level = 0
debug = true
split-debuginfo = "unpacked"

[profile.bench]
# Optimization for benchmarks
opt-level = 3
lto = true
codegen-units = 1

[features]
default = ["jemalloc"]
jemalloc = ["tikv-jemallocator"]
EOF
    
    # Create performance configuration
    mkdir -p "src/config"
    cat > "src/config/performance.rs" << 'EOF'
use std::time::Duration;

/// Performance configuration settings
#[derive(Debug, Clone)]
pub struct PerformanceConfig {
    pub database: DatabasePerformanceConfig,
    pub redis: RedisPerformanceConfig,
    pub server: ServerPerformanceConfig,
    pub echo_index: EchoIndexPerformanceConfig,
}

#[derive(Debug, Clone)]
pub struct DatabasePerformanceConfig {
    pub max_connections: u32,
    pub min_connections: u32,
    pub connection_timeout: Duration,
    pub idle_timeout: Duration,
    pub max_lifetime: Duration,
    pub acquire_timeout: Duration,
}

#[derive(Debug, Clone)]
pub struct RedisPerformanceConfig {
    pub max_connections: u32,
    pub connection_timeout: Duration,
    pub response_timeout: Duration,
    pub retry_attempts: usize,
}

#[derive(Debug, Clone)]
pub struct ServerPerformanceConfig {
    pub worker_threads: Option<usize>,
    pub max_blocking_threads: usize,
    pub request_timeout: Duration,
    pub keep_alive_timeout: Duration,
    pub max_concurrent_requests: usize,
}

#[derive(Debug, Clone)]
pub struct EchoIndexPerformanceConfig {
    pub batch_size: usize,
    pub calculation_timeout: Duration,
    pub cache_ttl: Duration,
    pub parallel_calculations: bool,
}

impl Default for PerformanceConfig {
    fn default() -> Self {
        Self {
            database: DatabasePerformanceConfig {
                max_connections: 100,
                min_connections: 5,
                connection_timeout: Duration::from_secs(30),
                idle_timeout: Duration::from_secs(300),
                max_lifetime: Duration::from_secs(3600),
                acquire_timeout: Duration::from_secs(30),
            },
            redis: RedisPerformanceConfig {
                max_connections: 50,
                connection_timeout: Duration::from_secs(10),
                response_timeout: Duration::from_secs(5),
                retry_attempts: 3,
            },
            server: ServerPerformanceConfig {
                worker_threads: None, // Use default (number of CPU cores)
                max_blocking_threads: 512,
                request_timeout: Duration::from_secs(30),
                keep_alive_timeout: Duration::from_secs(60),
                max_concurrent_requests: 10000,
            },
            echo_index: EchoIndexPerformanceConfig {
                batch_size: 100,
                calculation_timeout: Duration::from_secs(10),
                cache_ttl: Duration::from_secs(300),
                parallel_calculations: true,
            },
        }
    }
}

impl PerformanceConfig {
    pub fn from_env() -> Self {
        Self {
            database: DatabasePerformanceConfig {
                max_connections: std::env::var("DB_MAX_CONNECTIONS")
                    .unwrap_or_else(|_| "100".to_string())
                    .parse()
                    .unwrap_or(100),
                min_connections: std::env::var("DB_MIN_CONNECTIONS")
                    .unwrap_or_else(|_| "5".to_string())
                    .parse()
                    .unwrap_or(5),
                connection_timeout: Duration::from_secs(
                    std::env::var("DB_CONNECTION_TIMEOUT")
                        .unwrap_or_else(|_| "30".to_string())
                        .parse()
                        .unwrap_or(30),
                ),
                idle_timeout: Duration::from_secs(
                    std::env::var("DB_IDLE_TIMEOUT")
                        .unwrap_or_else(|_| "300".to_string())
                        .parse()
                        .unwrap_or(300),
                ),
                max_lifetime: Duration::from_secs(
                    std::env::var("DB_MAX_LIFETIME")
                        .unwrap_or_else(|_| "3600".to_string())
                        .parse()
                        .unwrap_or(3600),
                ),
                acquire_timeout: Duration::from_secs(
                    std::env::var("DB_ACQUIRE_TIMEOUT")
                        .unwrap_or_else(|_| "30".to_string())
                        .parse()
                        .unwrap_or(30),
                ),
            },
            redis: RedisPerformanceConfig {
                max_connections: std::env::var("REDIS_MAX_CONNECTIONS")
                    .unwrap_or_else(|_| "50".to_string())
                    .parse()
                    .unwrap_or(50),
                connection_timeout: Duration::from_secs(
                    std::env::var("REDIS_CONNECTION_TIMEOUT")
                        .unwrap_or_else(|_| "10".to_string())
                        .parse()
                        .unwrap_or(10),
                ),
                response_timeout: Duration::from_secs(
                    std::env::var("REDIS_RESPONSE_TIMEOUT")
                        .unwrap_or_else(|_| "5".to_string())
                        .parse()
                        .unwrap_or(5),
                ),
                retry_attempts: std::env::var("REDIS_RETRY_ATTEMPTS")
                    .unwrap_or_else(|_| "3".to_string())
                    .parse()
                    .unwrap_or(3),
            },
            server: ServerPerformanceConfig {
                worker_threads: std::env::var("SERVER_WORKER_THREADS")
                    .ok()
                    .and_then(|s| s.parse().ok()),
                max_blocking_threads: std::env::var("SERVER_MAX_BLOCKING_THREADS")
                    .unwrap_or_else(|_| "512".to_string())
                    .parse()
                    .unwrap_or(512),
                request_timeout: Duration::from_secs(
                    std::env::var("SERVER_REQUEST_TIMEOUT")
                        .unwrap_or_else(|_| "30".to_string())
                        .parse()
                        .unwrap_or(30),
                ),
                keep_alive_timeout: Duration::from_secs(
                    std::env::var("SERVER_KEEP_ALIVE_TIMEOUT")
                        .unwrap_or_else(|_| "60".to_string())
                        .parse()
                        .unwrap_or(60),
                ),
                max_concurrent_requests: std::env::var("SERVER_MAX_CONCURRENT_REQUESTS")
                    .unwrap_or_else(|_| "10000".to_string())
                    .parse()
                    .unwrap_or(10000),
            },
            echo_index: EchoIndexPerformanceConfig {
                batch_size: std::env::var("ECHO_INDEX_BATCH_SIZE")
                    .unwrap_or_else(|_| "100".to_string())
                    .parse()
                    .unwrap_or(100),
                calculation_timeout: Duration::from_secs(
                    std::env::var("ECHO_INDEX_CALCULATION_TIMEOUT")
                        .unwrap_or_else(|_| "10".to_string())
                        .parse()
                        .unwrap_or(10),
                ),
                cache_ttl: Duration::from_secs(
                    std::env::var("ECHO_INDEX_CACHE_TTL")
                        .unwrap_or_else(|_| "300".to_string())
                        .parse()
                        .unwrap_or(300),
                ),
                parallel_calculations: std::env::var("ECHO_INDEX_PARALLEL_CALCULATIONS")
                    .unwrap_or_else(|_| "true".to_string())
                    .parse()
                    .unwrap_or(true),
            },
        }
    }
}
EOF
    
    # Create memory profiling utilities
    cat > "src/utils/profiling.rs" << 'EOF'
#[cfg(feature = "jemalloc")]
use tikv_jemallocator::Jemalloc;

#[cfg(feature = "jemalloc")]
#[global_allocator]
static GLOBAL: Jemalloc = Jemalloc;

use std::time::{Duration, Instant};

/// Performance metrics collector
pub struct PerformanceMetrics {
    start_time: Instant,
    operation_name: String,
}

impl PerformanceMetrics {
    pub fn new(operation_name: &str) -> Self {
        Self {
            start_time: Instant::now(),
            operation_name: operation_name.to_string(),
        }
    }

    pub fn elapsed(&self) -> Duration {
        self.start_time.elapsed()
    }

    pub fn log_completion(&self) {
        let elapsed = self.elapsed();
        tracing::info!(
            operation = %self.operation_name,
            duration_ms = elapsed.as_millis(),
            "Operation completed"
        );
    }
}

impl Drop for PerformanceMetrics {
    fn drop(&mut self) {
        self.log_completion();
    }
}

/// Memory usage information
#[cfg(feature = "jemalloc")]
pub fn log_memory_usage() {
    use jemalloc_ctl::{stats, epoch};
    
    if let Ok(e) = epoch::mib() {
        let _ = e.advance();
    }
    
    if let (Ok(allocated), Ok(resident)) = (stats::allocated::read(), stats::resident::read()) {
        tracing::info!(
            allocated_mb = allocated / 1024 / 1024,
            resident_mb = resident / 1024 / 1024,
            "Memory usage"
        );
    }
}

#[cfg(not(feature = "jemalloc"))]
pub fn log_memory_usage() {
    tracing::warn!("Memory profiling not available without jemalloc feature");
}

/// Macro for easy performance monitoring
#[macro_export]
macro_rules! monitor_performance {
    ($name:expr, $code:block) => {{
        let _metrics = $crate::utils::profiling::PerformanceMetrics::new($name);
        $code
    }};
}
EOF
    
    print_success "Backend optimization configurations created"
    
    cd "$PROJECT_ROOT"
}

# ====================================
# MONITORING AND PROFILING SETUP
# ====================================
setup_monitoring() {
    print_header "MONITORING AND PROFILING SETUP"
    
    # Create performance monitoring Docker compose addition
    cat > "$PROJECT_ROOT/docker/docker-compose.monitoring.yml" << 'EOF'
version: '3.8'

services:
  # Application Performance Monitoring
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: echolayer-jaeger
    restart: unless-stopped
    ports:
      - "16686:16686"
      - "14268:14268"
    environment:
      COLLECTOR_OTLP_ENABLED: true
    networks:
      - internal

  # Metrics collection
  node-exporter:
    image: prom/node-exporter:latest
    container_name: echolayer-node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    networks:
      - internal

  # Database monitoring
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter
    container_name: echolayer-postgres-exporter
    restart: unless-stopped
    environment:
      DATA_SOURCE_NAME: postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?sslmode=disable
    depends_on:
      - postgres
    networks:
      - internal

  # Redis monitoring
  redis-exporter:
    image: oliver006/redis_exporter
    container_name: echolayer-redis-exporter
    restart: unless-stopped
    environment:
      REDIS_ADDR: redis:6379
      REDIS_PASSWORD: ${REDIS_PASSWORD}
    depends_on:
      - redis
    networks:
      - internal

networks:
  internal:
    external: true
    name: echolayer_internal
EOF
    
    # Create performance testing script
    cat > "$PROJECT_ROOT/scripts/performance-test.sh" << 'EOF'
#!/bin/bash

# Performance Testing Script for EchoLayer
set -e

echo "Starting EchoLayer Performance Tests..."

# Configuration
API_BASE_URL="http://localhost:8080"
FRONTEND_URL="http://localhost:3000"
CONCURRENT_USERS=50
TEST_DURATION=300  # 5 minutes

# Check if tools are available
command -v ab >/dev/null 2>&1 || { echo "Apache Bench (ab) is required but not installed."; exit 1; }
command -v curl >/dev/null 2>&1 || { echo "curl is required but not installed."; exit 1; }

echo "Running API performance tests..."

# Test health endpoint
echo "Testing health endpoint..."
ab -n 1000 -c 10 "$API_BASE_URL/health"

# Test authentication endpoint
echo "Testing authentication performance..."
ab -n 500 -c 5 -T 'application/json' -p /dev/stdin "$API_BASE_URL/auth/login" << 'JSON'
{
  "wallet_address": "test_wallet",
  "signature": "test_signature",
  "message": "test_message"
}
JSON

# Test Echo Index calculation
echo "Testing Echo Index calculation..."
ab -n 200 -c 5 "$API_BASE_URL/echo-index/calculate?content_id=test&platform=twitter"

# Frontend performance test
echo "Testing frontend performance..."
ab -n 500 -c 10 "$FRONTEND_URL/"

echo "Performance tests completed!"
EOF
    
    chmod +x "$PROJECT_ROOT/scripts/performance-test.sh"
    
    print_success "Monitoring and profiling setup created"
}

# ====================================
# MAIN EXECUTION
# ====================================
main() {
    print_header "ECHOLAYER PERFORMANCE OPTIMIZER"
    log "Starting performance optimization process"
    
    echo "This script will optimize the following components:"
    echo "1. Database (PostgreSQL)"
    echo "2. Cache (Redis)"
    echo "3. Frontend (Next.js)"
    echo "4. Backend (Rust)"
    echo "5. Monitoring & Profiling"
    echo ""
    
    # Execute optimizations
    optimize_database
    optimize_redis
    optimize_frontend
    optimize_backend
    setup_monitoring
    
    print_header "OPTIMIZATION COMPLETE"
    
    echo ""
    echo "🎉 Performance optimization completed successfully!"
    echo ""
    echo "Next steps:"
    echo "1. Review generated configuration files"
    echo "2. Apply database optimizations: psql \$DATABASE_URL -f temp_db_optimize.sql"
    echo "3. Update Redis configuration in docker-compose files"
    echo "4. Replace Next.js config with optimized version"
    echo "5. Update Cargo.toml with optimized dependencies"
    echo "6. Test performance improvements"
    echo ""
    echo "Monitoring:"
    echo "- Jaeger tracing: http://localhost:16686"
    echo "- Node metrics: Available via Prometheus"
    echo "- Run performance tests: ./scripts/performance-test.sh"
    echo ""
    
    log "Performance optimization process completed successfully"
}

# Run main function
main "$@" 